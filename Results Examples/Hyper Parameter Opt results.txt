
-same random state

mlp rgr, activation = identity:  std:0.017718600626384196 : 0.6536679536679536
mlp rgr, activation = logistic:  std:0.01617018655704397 : 0.6528957528957529
mlp rgr, activation = tanh:  std:0.022159605949469866 : 0.6471042471042472
mlp rgr, activation = relu:  std:0.0147225297026545 : 0.6741312741312742

mlp rgr, solver = lbfgs:  std:0.012653258384690275 : 0.6637065637065637
mlp rgr, solver = sgd:  std:0.015171337995666796 : 0.5467181467181467
mlp rgr , solver = adam:  std:0.019815640803639126 : 0.6714285714285714

mlp rgr, learning rate = : constant std:0.01656186145909437 : 0.6756756756756757
mlp rgr, learning rate = : invscaling std:0.017541029639537492 : 0.6683397683397684
mlp rgr, learning rate = : adaptive std:0.008685113420233183 : 0.6671814671814672

mlp rgr, learning rate init = : 00001 std:0.019535306008762215 : 0.6583011583011583
mlp rgr, learning rate init = : 0001 std:0.02077062186303129 : 0.677992277992278
mlp rgr, learning rate init = : 001 std:0.01955818554735743 : 0.6749034749034749
mlp rgr, learning rate init = : 01 std:0.13139558315453867 : 0.5613899613899613

mlp rgr, max_iter = 50: std:0.01706720934772227 : 0.6714285714285714
mlp rgr, max_iter = 100: std:0.03252423117938639 : 0.6671814671814672
mlp rgr, max_iter = 150: std:0.017119536121540824 : 0.6671814671814672
mlp rgr, max_iter = 200: std:0.013650710061516335 : 0.667953667953668
mlp rgr, max_iter = 250: std:0.0019687334029315734 : 0.6745173745173745
mlp rgr, max_iter = 50: std:0.015230179863564463 : 0.6671814671814672
mlp rgr, max_iter = 100: std:0.02133706853999709 : 0.6683397683397683
mlp rgr, max_iter = 150: std:0.01636264100418309 : 0.6671814671814673
mlp rgr, max_iter = 200: std:0.012246140175408243 : 0.6745173745173745
mlp rgr, max_iter = 250: std:0.009005331111730176 : 0.6752895752895752
mlp rgr, max_iter = 300: std:0.025377106911436277 : 0.6698841698841699

mlp rgr, shuffle = true: std:0.01639904292015078 : 0.6733590733590733
mlp rgr, shuffle = false: std:0.014783158084229073 : 0.6783783783783783

mlp rgr, hidden_layer = 100: std:0.02094928180115915 : 0.6694980694980694
mlp rgr, hidden_layer = 500: std:0.020525148818535927 : 0.6710424710424711
mlp rgr, hidden_layer = 800: std:0.012475285267493036 : 0.6683397683397685
mlp rgr, hidden_layer = 1000: std:0.008922177612580169 : 0.6702702702702702
mlp rgr, hidden_layer = 1500: std:0.026805490282177286 : 0.6718146718146718
mlp rgr, hidden_layer = 2000: std:0.01596607963562571 : 0.667953667953668
mlp rgr, hidden_layer = 3000: std:0.02271110605382662 : 0.6737451737451737
mlp rgr, hidden_layer = 100,100,100,100: std:0.016579853709331193 : 0.6675675675675675